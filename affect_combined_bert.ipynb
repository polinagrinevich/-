{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T19:23:05.077167Z",
     "iopub.status.busy": "2024-06-13T19:23:05.075420Z",
     "iopub.status.idle": "2024-06-13T19:23:05.115780Z",
     "shell.execute_reply": "2024-06-13T19:23:05.114829Z",
     "shell.execute_reply.started": "2024-06-13T19:23:05.077109Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import softmax\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AdamW, \n",
    "    get_linear_schedule_with_warmup, \n",
    "    BertModel, \n",
    "    BertTokenizer, \n",
    "    BertPreTrainedModel, \n",
    "    BertConfig, \n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Предобработка текста:\n",
    "    - Удаление меток ID в начале строки\n",
    "    - Удаление табуляций и переводов строк\n",
    "    \"\"\"\n",
    "    if text.startswith('[id'):\n",
    "        text = re.sub(r'\\[.*?,', '', text)\n",
    "    \n",
    "    text = re.sub(r'[\\t\\n]', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, \n",
    "          optimizer: torch.optim, \n",
    "          scheduler: torch.optim, \n",
    "          train_loader: DataLoader, \n",
    "          test_loader: DataLoader, \n",
    "          criterion_isr: nn.Module, \n",
    "          criterion_pal: nn.Module, \n",
    "          epochs: int, \n",
    "          acc_max: float) -> None:\n",
    "\n",
    "\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        curr_train_acc = []\n",
    "        curr_train_loss = []\n",
    "\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch['input_ids'].squeeze(1).to(device)\n",
    "            attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
    "            labels_isr = batch['labels_isr'].long().to(device)\n",
    "            labels_pal = batch['labels_pal'].long().to(device)\n",
    "\n",
    "            # Прямой проход модели\n",
    "            outputs_isr, outputs_pal = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            # Предсказания и вычисление потерь\n",
    "            logits_isr = outputs_isr.detach().cpu().numpy()\n",
    "            logits_pal = outputs_pal.detach().cpu().numpy()\n",
    "            pred_tr_isr = np.argmax(logits_isr, axis=1)\n",
    "            pred_tr_pal = np.argmax(logits_pal, axis=1)\n",
    "\n",
    "            loss_isr = criterion_isr(outputs_isr, labels_isr)\n",
    "            loss_pal = criterion_pal(outputs_pal, labels_pal)\n",
    "            loss = loss_isr + loss_pal\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            curr_train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "            # Вычисление точности\n",
    "            acc = np.sum((pred_tr_isr == labels_isr.detach().cpu().numpy()) & \n",
    "                         (pred_tr_pal == labels_pal.detach().cpu().numpy())) / len(labels_isr)\n",
    "            curr_train_acc.append(acc)\n",
    "            train_acc.append(acc)\n",
    "\n",
    "        print('Epoch: ', epoch + 1)\n",
    "        print(f'Train loss: {sum(curr_train_loss) / len(train_loader)}')\n",
    "        print(f'Train accuracy: {np.mean(curr_train_acc)}')\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        test_acc = []\n",
    "        true_labels_isr = []\n",
    "        pred_all_isr = []\n",
    "        true_labels_pal = []\n",
    "        pred_all_pal = []\n",
    "\n",
    "        \n",
    "        # Оценка модели на тестовой выборке\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                input_ids = batch['input_ids'].squeeze(1).to(device)\n",
    "                attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
    "                labels_isr = batch['labels_isr'].long().to(device)\n",
    "                labels_pal = batch['labels_pal'].long().to(device)\n",
    "\n",
    "                # Прямой проход модели\n",
    "                outputs_isr, outputs_pal = model(input_ids, attention_mask)\n",
    "\n",
    "                # Вычисление потерь\n",
    "                loss_isr = criterion_isr(outputs_isr, labels_isr)\n",
    "                loss_pal = criterion_pal(outputs_pal, labels_pal)\n",
    "                loss = loss_isr + loss_pal\n",
    "                test_loss.append(loss.item())\n",
    "\n",
    "                logits_isr = outputs_isr.detach().cpu().numpy()\n",
    "                pred_test_isr = np.argmax(logits_isr, axis=1)\n",
    "\n",
    "                true_labels_isr += labels_isr.tolist()\n",
    "                pred_all_isr += pred_test_isr.tolist()\n",
    "                \n",
    "                logits_pal = outputs_pal.detach().cpu().numpy()\n",
    "                pred_test_pal = np.argmax(logits_pal, axis=1)\n",
    "\n",
    "                true_labels_pal += labels_pal.tolist()\n",
    "                pred_all_pal += pred_test_pal.tolist()\n",
    "\n",
    "            avg_test_loss = sum(test_loss) / len(test_loader)\n",
    "            avg_test_acc = np.mean((np.array(true_labels_isr) == np.array(pred_all_isr)) & \n",
    "                                   (np.array(true_labels_pal) == np.array(pred_all_pal)))\n",
    "\n",
    "\n",
    "            print(f'\\nTest loss: {avg_test_loss}')\n",
    "            print(f'Test accuracy: {avg_test_acc}\\n')\n",
    "            \n",
    "            if avg_test_acc > acc_max:\n",
    "                print(classification_report(true_labels_isr, pred_all_isr), '\\n')\n",
    "                print(classification_report(true_labels_pal, pred_all_pal), '\\n')\n",
    "                return\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                print(classification_report(true_labels_isr, pred_all_isr), '\\n')\n",
    "                print(classification_report(true_labels_pal, pred_all_pal), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T19:23:06.739119Z",
     "iopub.status.busy": "2024-06-13T19:23:06.737863Z",
     "iopub.status.idle": "2024-06-13T19:23:06.752118Z",
     "shell.execute_reply": "2024-06-13T19:23:06.751329Z",
     "shell.execute_reply.started": "2024-06-13T19:23:06.739074Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(data: pd.DataFrame, \n",
    "             tokenizer: AutoTokenizer, \n",
    "             loader=True, \n",
    "             batch_size=16, \n",
    "             shuffle=True):\n",
    "\n",
    "    '''\n",
    "    Токенизация текста\n",
    "    - loader: если True, то вернуть формат DataLoader, в ином случае - список из словарей\n",
    "    - shuffle: передается в DataLoader\n",
    "    '''\n",
    "\n",
    "    data_tokenized = []\n",
    "    \n",
    "    for i, row in tqdm(data.iterrows()):\n",
    "        inputs = tokenizer.encode_plus(\n",
    "                row['text'],\n",
    "                add_special_tokens=True,\n",
    "                truncation=True,\n",
    "                max_length=256,\n",
    "                padding='max_length',\n",
    "                return_attention_mask = True,\n",
    "                return_tensors = 'pt',\n",
    "            )\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        labels_isr = row['affect_isr']\n",
    "        labels_pal = row['affect_pal']\n",
    "        \n",
    "        final = {\n",
    "                'input_ids': ids.clone().detach(),\n",
    "                'attention_mask': mask.clone().detach(),\n",
    "                'labels_isr': torch.tensor(labels_isr, dtype=torch.float),\n",
    "                'labels_pal': torch.tensor(labels_pal, dtype=torch.float)\n",
    "            }\n",
    "\n",
    "        data_tokenized.append(final)\n",
    "\n",
    "\n",
    "        dataloader = DataLoader(data_tokenized, batch_size=16, shuffle=shuffle)\n",
    "    \n",
    "    if loader:\n",
    "        return dataloader\n",
    "    else:\n",
    "        return data_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T20:11:24.425474Z",
     "iopub.status.busy": "2024-06-13T20:11:24.424349Z",
     "iopub.status.idle": "2024-06-13T20:11:24.453742Z",
     "shell.execute_reply": "2024-06-13T20:11:24.452843Z",
     "shell.execute_reply.started": "2024-06-13T20:11:24.425427Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test(df: pd.DataFrame, aug: pd.DataFrame, test_size: float, augs=None):\n",
    "\n",
    "    '''\n",
    "    Раздление на тренировочную и тестовую выборки, добавление аугментаций\n",
    "    - augs: если True, то к тренировочную набору данных добавляются аугментации\n",
    "    - aug: массив аугментированных данных\n",
    "    '''\n",
    "    \n",
    "    X_train, X_test = train_test_split(df, test_size=test_size, stratify=df[['affect_isr', 'affect_pal']], random_state=1907)\n",
    "\n",
    "    X_train['affect_isr'] = X_train['affect_isr'].astype(int)\n",
    "    X_test['affect_isr'] = X_test['affect_isr'].astype(int)\n",
    "    \n",
    "    X_train['affect_pal'] = X_train['affect_pal'].astype(int)\n",
    "    X_test['affect_pal'] = X_test['affect_pal'].astype(int)\n",
    "    \n",
    "    \n",
    "    if augs:\n",
    "        X_train = pd.concat((aug, X_train))\n",
    "\n",
    "        \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# affect models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T19:58:22.218693Z",
     "iopub.status.busy": "2024-06-13T19:58:22.217544Z",
     "iopub.status.idle": "2024-06-13T19:58:22.326923Z",
     "shell.execute_reply": "2024-06-13T19:58:22.326142Z",
     "shell.execute_reply.started": "2024-06-13T19:58:22.218647Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('df.csv')\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "df_test = pd.read_csv('df_test.csv')\n",
    "df_test['text'] = df_test['text'].apply(preprocess_text)\n",
    "\n",
    "aug = pd.read_csv('aug.csv')\n",
    "aug['text'] = aug['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T19:58:23.014476Z",
     "iopub.status.busy": "2024-06-13T19:58:23.013274Z",
     "iopub.status.idle": "2024-06-13T19:58:23.041396Z",
     "shell.execute_reply": "2024-06-13T19:58:23.040623Z",
     "shell.execute_reply.started": "2024-06-13T19:58:23.014431Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertForMultiTaskClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "\n",
    "\n",
    "        self.classifier1 = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config.hidden_size, 3),\n",
    "        )\n",
    "        \n",
    "        self.classifier2 = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config.hidden_size, 3),\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels1=None, labels2=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        logits1 = self.classifier1(pooled_output)\n",
    "        logits2 = self.classifier2(pooled_output)\n",
    "\n",
    "        return logits1, logits2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T19:54:45.245438Z",
     "iopub.status.busy": "2024-06-13T19:54:45.244141Z",
     "iopub.status.idle": "2024-06-13T19:54:46.240967Z",
     "shell.execute_reply": "2024-06-13T19:54:46.239972Z",
     "shell.execute_reply.started": "2024-06-13T19:54:45.245401Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# очистка памяти \n",
    "model.cpu()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## affect isr model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T20:24:24.172386Z",
     "iopub.status.busy": "2024-06-13T20:24:24.171110Z",
     "iopub.status.idle": "2024-06-13T20:36:18.499676Z",
     "shell.execute_reply": "2024-06-13T20:36:18.498765Z",
     "shell.execute_reply.started": "2024-06-13T20:24:24.172335Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87947c016bb24557800cd83408a76e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9338d17f2643379fe2ff81003eb866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultiTaskClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier1.0.bias', 'classifier1.0.weight', 'classifier1.2.bias', 'classifier1.2.weight', 'classifier2.0.bias', 'classifier2.0.weight', 'classifier2.2.bias', 'classifier2.2.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Train loss: 1.4939720804492633\n",
      "Train accuracy: 0.4523467432950191\n",
      "\n",
      "Test loss: 1.1956732564194257\n",
      "Test accuracy: 0.5976505139500734\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.41      0.49        58\n",
      "           1       0.73      0.66      0.69       268\n",
      "           2       0.73      0.82      0.77       355\n",
      "\n",
      "    accuracy                           0.72       681\n",
      "   macro avg       0.68      0.63      0.65       681\n",
      "weighted avg       0.72      0.72      0.71       681\n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.19      0.29        85\n",
      "           1       0.61      0.51      0.56        69\n",
      "           2       0.84      0.95      0.89       527\n",
      "\n",
      "    accuracy                           0.81       681\n",
      "   macro avg       0.69      0.55      0.58       681\n",
      "weighted avg       0.79      0.81      0.78       681\n",
      " \n",
      "\n",
      "Epoch:  2\n",
      "Train loss: 0.8805948005582409\n",
      "Train accuracy: 0.7209650383141762\n",
      "\n",
      "Test loss: 1.1612868350605632\n",
      "Test accuracy: 0.6358296622613803\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.53      0.55        58\n",
      "           1       0.71      0.71      0.71       268\n",
      "           2       0.77      0.77      0.77       355\n",
      "\n",
      "    accuracy                           0.73       681\n",
      "   macro avg       0.68      0.67      0.68       681\n",
      "weighted avg       0.73      0.73      0.73       681\n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.49      0.53        85\n",
      "           1       0.73      0.43      0.55        69\n",
      "           2       0.87      0.93      0.90       527\n",
      "\n",
      "    accuracy                           0.83       681\n",
      "   macro avg       0.72      0.62      0.66       681\n",
      "weighted avg       0.82      0.83      0.82       681\n",
      " \n",
      "\n",
      "Epoch:  3\n",
      "Train loss: 0.4708122234663059\n",
      "Train accuracy: 0.8640445402298851\n",
      "\n",
      "Test loss: 1.2467979088772174\n",
      "Test accuracy: 0.6299559471365639\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.59        58\n",
      "           1       0.74      0.67      0.70       268\n",
      "           2       0.75      0.80      0.77       355\n",
      "\n",
      "    accuracy                           0.73       681\n",
      "   macro avg       0.69      0.69      0.69       681\n",
      "weighted avg       0.73      0.73      0.73       681\n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53        85\n",
      "           1       0.61      0.49      0.54        69\n",
      "           2       0.88      0.91      0.89       527\n",
      "\n",
      "    accuracy                           0.82       681\n",
      "   macro avg       0.67      0.64      0.65       681\n",
      "weighted avg       0.81      0.82      0.81       681\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"DeepPavlov/rubert-base-cased-conversational\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "X_train, X_test = train_test(df.copy(), aug.copy(),  0.15, True)\n",
    "\n",
    "X_train.to_csv('X_train.csv')\n",
    "X_test.to_csv('X_test.csv')\n",
    "\n",
    "train_dataloader = tokenize(X_train, tokenizer, batch_size=64, shuffle=True)\n",
    "test_dataloader = tokenize(X_test,  tokenizer, batch_size=64, shuffle=False)\n",
    "\n",
    "config = BertConfig.from_pretrained(checkpoint)\n",
    "config.num_labels = 3  \n",
    "\n",
    "model = BertForMultiTaskClassification.from_pretrained(checkpoint, config=config)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion_isr = nn.CrossEntropyLoss()\n",
    "criterion_pal = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 4e-5, no_deprecation_warning=True)\n",
    "num_epochs = 3\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1 * total_steps, num_training_steps=total_steps)\n",
    "\n",
    "\n",
    "train(model, optimizer, scheduler, train_dataloader, test_dataloader, criterion_isr, criterion_pal, num_epochs, acc_max=0.73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T20:36:27.720666Z",
     "iopub.status.busy": "2024-06-13T20:36:27.719650Z",
     "iopub.status.idle": "2024-06-13T20:36:32.594916Z",
     "shell.execute_reply": "2024-06-13T20:36:32.593980Z",
     "shell.execute_reply.started": "2024-06-13T20:36:27.720622Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'model_FINAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T20:36:36.942477Z",
     "iopub.status.busy": "2024-06-13T20:36:36.941304Z",
     "iopub.status.idle": "2024-06-13T20:36:36.965471Z",
     "shell.execute_reply": "2024-06-13T20:36:36.964720Z",
     "shell.execute_reply.started": "2024-06-13T20:36:36.942432Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(test, model):\n",
    "    logits_isr, logits_pal = [], []\n",
    "    preds_isr, preds_pal = [], []\n",
    "\n",
    "    for i in tqdm(test):\n",
    "    \n",
    "        ids = i['input_ids'].clone().detach().to(device)\n",
    "        mask = i['attention_mask'].clone().detach().to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(ids, mask)\n",
    "            logit_isr, logit_pal = output\n",
    "            logit_isr, logit_pal = logit_isr.detach().cpu().numpy(), logit_pal.detach().cpu().numpy()\n",
    "            \n",
    "            logits_isr.append(logit_isr[0])\n",
    "            logits_pal.append(logit_pal[0])\n",
    "            preds_isr.append(np.argmax(logit_isr, axis=1))\n",
    "            preds_pal.append(np.argmax(logit_pal, axis=1))\n",
    "\n",
    "    return logits_isr, logits_pal, preds_isr, preds_pal   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T20:36:37.792746Z",
     "iopub.status.busy": "2024-06-13T20:36:37.791551Z",
     "iopub.status.idle": "2024-06-13T20:36:46.664865Z",
     "shell.execute_reply": "2024-06-13T20:36:46.663974Z",
     "shell.execute_reply.started": "2024-06-13T20:36:37.792701Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff7a58b3c02424ea380b661282ca601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee426013d74410e99cf634affbcb040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model1 = torch.load('model11')\n",
    "# model2 = torch.load('model22')\n",
    "\n",
    "test1 = tokenize(df_test, tokenizer, shuffle=False, loader=False)\n",
    "logits_isr, logits_pal, preds_isr, preds_pal = evaluate(test1, model)\n",
    "# logits2, preds2 = evaluate(test2, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T20:36:46.666792Z",
     "iopub.status.busy": "2024-06-13T20:36:46.666236Z",
     "iopub.status.idle": "2024-06-13T20:36:46.720725Z",
     "shell.execute_reply": "2024-06-13T20:36:46.719927Z",
     "shell.execute_reply.started": "2024-06-13T20:36:46.666756Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60        89\n",
      "           1       0.75      0.79      0.77       242\n",
      "           2       0.67      0.67      0.67       170\n",
      "\n",
      "    accuracy                           0.71       501\n",
      "   macro avg       0.69      0.67      0.68       501\n",
      "weighted avg       0.71      0.71      0.71       501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def attitude_pred(x):\n",
    "    if x['pred_ai'] == x['pred_ap']:\n",
    "        return(x['pred_ap'][0])\n",
    "    elif x['pred_ap'] == 2 or x['pred_ai'] == 2:\n",
    "        return min(x['pred_ai'], x['pred_ap'])[0]\n",
    "    else:\n",
    "        return 2\n",
    "            \n",
    "\n",
    "df_test['pred_ai'] = preds_isr\n",
    "df_test['pred_ap'] = preds_pal\n",
    "df_test['pred_a'] = df_test.apply(attitude_pred, axis=1)\n",
    "\n",
    "print(classification_report(df_test['attitude'], df_test['pred_a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T15:30:40.438912Z",
     "iopub.status.busy": "2024-06-13T15:30:40.437711Z",
     "iopub.status.idle": "2024-06-13T15:30:40.515334Z",
     "shell.execute_reply": "2024-06-13T15:30:40.514444Z",
     "shell.execute_reply.started": "2024-06-13T15:30:40.438868Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test['pred_ai'] = [i[0] for i in df_test['pred_ai']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T15:30:44.257774Z",
     "iopub.status.busy": "2024-06-13T15:30:44.256661Z",
     "iopub.status.idle": "2024-06-13T15:30:44.297542Z",
     "shell.execute_reply": "2024-06-13T15:30:44.296635Z",
     "shell.execute_reply.started": "2024-06-13T15:30:44.257730Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test['pred_ap'] = [i[0] for i in df_test['pred_ap']]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "J0pT37WS1Uk9",
    "2fBd6kkV1ZSt",
    "k22Q0RS3Dftf",
    "uKt0DnoXPmJD",
    "xWkScUI9_MiW",
    "pRNx5084QGNc",
    "rKxuWwz7tWyQ",
    "kcteM2QtkeVe",
    "raaam6alN97t",
    "88L5iu551hGo",
    "mV4Ocx46Mv9I",
    "8J4weDrkNAXQ",
    "AqUBRCGYD3oE"
   ],
   "name": "Copy of Deep_Tweet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
