{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c95fb65d-be1f-4d43-b338-ef1aa23d2197",
   "metadata": {},
   "source": [
    "# Отбор релевантных данных\n",
    "\n",
    "На этом этапе мы чистим данные и убираем нерелевантные посты и нерелевантные комментарии. \n",
    "\n",
    "Условия релевантности поста следующие:\n",
    "\n",
    "- в посте встречаются 2 и более ключевых слов\n",
    "- в посте встречается хотя бы одно ключевое слово и хотя бы одно контекстное\n",
    "\n",
    "Условие релевантности поста комментария:\n",
    "\n",
    "- в комментарии встречается хотя бы одно ключевое слово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc00f273-3447-4ebf-9046-231e01a419b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:25:13.307701Z",
     "iopub.status.busy": "2024-06-14T16:25:13.306431Z",
     "iopub.status.idle": "2024-06-14T16:25:22.690632Z",
     "shell.execute_reply": "2024-06-14T16:25:22.689980Z",
     "shell.execute_reply.started": "2024-06-14T16:25:13.307646Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import re\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "morph = MorphAnalyzer()\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "df = pl.read_parquet('comm_with_posts_final_10_3.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f0fdbd-cb2b-475a-81c9-9f530a462309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:25:22.692413Z",
     "iopub.status.busy": "2024-06-14T16:25:22.691996Z",
     "iopub.status.idle": "2024-06-14T16:25:22.712353Z",
     "shell.execute_reply": "2024-06-14T16:25:22.711789Z",
     "shell.execute_reply.started": "2024-06-14T16:25:22.692381Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('kw_pol.txt', 'r', encoding='utf-8') as f:\n",
    "    kw_new = f.read().split('\\n')\n",
    "\n",
    "with open('kw_context.txt', 'r', encoding='utf-8') as f:\n",
    "    kw_context = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a24485-26b5-4076-b5fa-ad5891511551",
   "metadata": {},
   "source": [
    "## Обработка текста\n",
    "\n",
    "- удаление отметок других пользователей\n",
    "- приведение к нижнему регистру\n",
    "- удаление табляций и перенос строк\n",
    "- удаление знаков препинания\n",
    "- удаление цифр\n",
    "- удаление стоп-сов\n",
    "- лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8e91d2-e441-4fbe-ad55-9aea10793cc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:25:22.714095Z",
     "iopub.status.busy": "2024-06-14T16:25:22.713231Z",
     "iopub.status.idle": "2024-06-14T16:25:25.345283Z",
     "shell.execute_reply": "2024-06-14T16:25:25.344535Z",
     "shell.execute_reply.started": "2024-06-14T16:25:22.714060Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Определение русских стоп-слов\n",
    "stop_words = stopwords.words('russian')\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Удаление упоминаний других пользователей\n",
    "    if text.startswith('[id'):\n",
    "        text = re.sub(\"\\[.*?\\,\", \"\", text)\n",
    "        \n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "\n",
    "    # Удаление табуляций и переносов строк\n",
    "    text = re.sub(r'[\\t\\n]', ' ', text)\n",
    "\n",
    "    # Удаление знаков препинания\n",
    "    text = re.sub(f\"[{re.escape(punctuation)}]\", \" \", text)\n",
    "\n",
    "    # Удаление цифр\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "\n",
    "    # Токенизация текста\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Удаление стоп-слов и лемматизация\n",
    "    tokens = [morph.parse(token)[0].normal_form for token in tokens if token not in stop_words]\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8284591e-1625-42fd-bef3-a3669f6132a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:25:25.347413Z",
     "iopub.status.busy": "2024-06-14T16:25:25.346953Z",
     "iopub.status.idle": "2024-06-14T16:25:25.366305Z",
     "shell.execute_reply": "2024-06-14T16:25:25.365634Z",
     "shell.execute_reply.started": "2024-06-14T16:25:25.347381Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_kw(x):\n",
    "    count = 0\n",
    "    for i in kw_new:\n",
    "        if str(i) in x:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def find_context(x):\n",
    "    count = 0\n",
    "    for i in kw_context:\n",
    "        if str(i) in x:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c77ed-20b1-45c0-9760-5285cd80c2f0",
   "metadata": {},
   "source": [
    "# Фильтрация постов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f967c-5f63-418e-a61d-37d666369d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns([\n",
    "    pl.col(\"post_text\").apply(preprocess_text).alias(\"cleaned_post\"), # обрабатываем текст поста\n",
    "    \n",
    "    pl.col(\"cleaned_post\").apply(find_kw).alias(\"kw_count_post\"), # считаем количество ключевых слов\n",
    "    \n",
    "    pl.col(\"cleaned_post\").apply(find_context).alias(\"context_count_post\") # считаем количество контекстных слов\n",
    "])\n",
    "\n",
    "# фильтруем посты\n",
    "df = df.filter((pl.col('kw_count_post') >= 2) | \n",
    "                ((pl.col('kw_count_post') >= 1) & (pl.col('context_count_post') >= 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363fa148-2d05-4688-8ebd-c1f24fe9be05",
   "metadata": {},
   "source": [
    "# Фильтрация комментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd5c8b-a9be-403e-9885-5bad991742fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:47:34.806688Z",
     "iopub.status.busy": "2024-06-14T16:47:34.805876Z",
     "iopub.status.idle": "2024-06-14T16:48:08.276518Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1706/1965607339.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['cleaned_comm'] = df1['text'].apply(preprocess_text)\n",
      "/tmp/ipykernel_1706/1965607339.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['kw_count'] = df1['cleaned_comm'].apply(find_kw)\n",
      "/tmp/ipykernel_1706/1965607339.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['context_count'] = df1['cleaned_comm'].apply(find_context)\n"
     ]
    }
   ],
   "source": [
    "df = df.with_columns([\n",
    "    pl.col(\"text\").apply(preprocess_text).alias(\"cleaned_comm\"), # обрабатываем текст комментария\n",
    "    \n",
    "    pl.col(\"cleaned_comm\").apply(find_kw).alias(\"kw_count\") # считаем количество ключевых слов\n",
    "\n",
    "])\n",
    "\n",
    "# фильтруем посты\n",
    "df = df.filter(pl.col('kw_count') >= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42017b3f-d44f-4e20-8f92-bdf5ef287546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T16:52:33.705436Z",
     "iopub.status.busy": "2024-06-14T16:52:33.704209Z",
     "iopub.status.idle": "2024-06-14T16:52:38.511954Z",
     "shell.execute_reply": "2024-06-14T16:52:38.511276Z",
     "shell.execute_reply.started": "2024-06-14T16:52:33.705398Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('filtered_pol_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
